# snow_dq_enhanced.py
# Run with: streamlit run snow_dq_enhanced.py
"""
SNOW Data Quality & Blast Radius - Enhanced Professional Edition

New Features:
- Modern, bright professional UI with vibrant color scheme
- VARCHAR analysis: min/max length of actual data
- Data duplication detection
- Leading/trailing space detection
- Special character detection
- Whitespace analysis
"""

import os
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st
from trino.dbapi import connect
from trino.auth import BasicAuthentication

# =========================
# Configuration
# =========================
HOST = "ai2025-free-cluster.trino.galaxy.starburst.io"
USER = "rahul.yaksh@bofa.com/accountadmin"
PASSWORD = "Aarush2011@"

APP_TITLE = "SNOW Data Quality Platform"
DEFAULT_PREVIEW = 50
DEFAULT_WORKERS = min(16, max(4, (os.cpu_count() or 8)))

cache_data = getattr(st, "cache_data", st.cache_data) if hasattr(st, "cache_data") else st.cache_data
cache_resource = getattr(st, "cache_resource", st.cache_resource) if hasattr(st, "cache_resource") else st.cache

# Catalog/schema filters
CATALOG_DENYLIST = {"system", "jmx", "galaxy"}
SCHEMA_DENY_EXACT = {"information_schema"}
SCHEMA_DENY_PREFIXES = ("information_schema", "_information_schema")

# Relationship threshold
JACCARD_THRESHOLD = 0.35


# =========================
# Utilities
# =========================
def qident(name: str) -> str:
    """Quote identifiers safely for Trino."""
    if name.startswith('"') and name.endswith('"'):
        return name
    return '"' + name.replace('"', '""') + '"'


@cache_resource(show_spinner=False)
def get_connection():
    return connect(
        host=HOST,
        port=443,
        user=USER,
        http_scheme="https",
        auth=BasicAuthentication(USER, PASSWORD),
    )


def run_sql(sql: str) -> Tuple[List[Tuple], List[str]]:
    conn = get_connection()
    cur = conn.cursor()
    cur.execute(sql)
    rows = cur.fetchall()
    cols = [d[0] for d in cur.description]
    return rows, cols


def is_allowed_catalog(name: str) -> bool:
    return name and name.lower() not in CATALOG_DENYLIST


def is_allowed_schema(name: str) -> bool:
    lname = (name or "").lower()
    if lname in SCHEMA_DENY_EXACT:
        return False
    return not any(lname.startswith(p) for p in SCHEMA_DENY_PREFIXES)


def ensure_arrow_compat(df: pd.DataFrame) -> pd.DataFrame:
    """Sanitize DataFrame for Streamlit/Arrow serialization."""
    if df is None or df.empty:
        return df
    out = df.copy()
    for col in out.columns:
        if out[col].dtype == "object":
            out[col] = out[col].apply(
                lambda x: x.decode("utf-8", "replace") if isinstance(x, (bytes, bytearray))
                else (str(x) if isinstance(x, (dict, list, set, tuple, complex)) else x)
            )
    return out.where(pd.notnull(out), None)


# =========================
# Metadata Helpers
# =========================
@cache_data(ttl=900, show_spinner=False)
def list_catalogs() -> List[str]:
    rows, _ = run_sql("SHOW CATALOGS")
    cats = sorted([r[0] for r in rows if is_allowed_catalog(r[0])])
    return cats


@cache_data(ttl=900, show_spinner=False)
def list_schemas(catalog: str) -> List[str]:
    rows, _ = run_sql(f"SHOW SCHEMAS FROM {qident(catalog)}")
    schemas = sorted([r[0] for r in rows if is_allowed_schema(r[0])])
    return schemas


@cache_data(ttl=900, show_spinner=False)
def list_tables(catalog: str, schema: str) -> List[str]:
    rows, _ = run_sql(f"SHOW TABLES FROM {qident(catalog)}.{qident(schema)}")
    return sorted([r[0] for r in rows])


@cache_data(ttl=900, show_spinner=False)
def get_columns(catalog: str, schema: str, table: str) -> pd.DataFrame:
    """Return columns dataframe with data types."""
    sql = f"""
    SELECT
      table_name,
      column_name,
      data_type,
      ordinal_position
    FROM {qident(catalog)}.information_schema.columns
    WHERE table_schema = {repr(schema)} AND table_name = {repr(table)}
    ORDER BY ordinal_position
    """
    rows, cols = run_sql(sql)
    return pd.DataFrame(rows, columns=cols)


@cache_data(ttl=900, show_spinner=False)
def get_all_columns_in_schema(catalog: str, schema: str) -> pd.DataFrame:
    """Returns columns for ALL tables within a schema."""
    sql = f"""
    SELECT
      table_name,
      column_name,
      data_type,
      ordinal_position
    FROM {qident(catalog)}.information_schema.columns
    WHERE table_schema = {repr(schema)}
    """
    rows, cols = run_sql(sql)
    return pd.DataFrame(rows, columns=cols)


@cache_data(ttl=900, show_spinner=False)
def preview_table(catalog: str, schema: str, table: str, limit: int = DEFAULT_PREVIEW) -> pd.DataFrame:
    q = f"SELECT * FROM {qident(catalog)}.{qident(schema)}.{qident(table)} LIMIT {int(limit)}"
    rows, cols = run_sql(q)
    return pd.DataFrame(rows, columns=cols)


@cache_data(ttl=300, show_spinner=False)
def table_has_rows(catalog: str, schema: str, table: str) -> bool:
    """Check if table has at least one row."""
    fq = f"{qident(catalog)}.{qident(schema)}.{qident(table)}"
    try:
        rows, _ = run_sql(f"SELECT 1 FROM {fq} LIMIT 1")
        return len(rows) > 0
    except Exception:
        return True


# =========================
# Enhanced Data Quality
# =========================
def _dq_sql_for_column(catalog: str, schema: str, table: str, col: str, data_type: str) -> str:
    """
    Build enhanced per-column stats query with advanced checks:
    - Basic: total_rows, null_count, approx_unique_count, min, max
    - VARCHAR specific: min_length, max_length
    - Quality: duplicate_count, leading_space_count, trailing_space_count, 
               special_char_count, whitespace_count
    """
    fq = f'{qident(catalog)}.{qident(schema)}.{qident(table)}'
    col_q = qident(col)
    
    # Base statistics
    base_stats = f"""
    {repr(col)} AS column_name,
    {repr(data_type)} AS data_type,
    COUNT(*) AS total_rows,
    SUM(CASE WHEN {col_q} IS NULL THEN 1 ELSE 0 END) AS null_count,
    APPROX_DISTINCT({col_q}, 0.01) AS approx_unique_count,
    CAST(TRY(MIN({col_q})) AS VARCHAR) AS min_value,
    CAST(TRY(MAX({col_q})) AS VARCHAR) AS max_value
    """
    
    # VARCHAR-specific length analysis
    is_varchar = 'varchar' in data_type.lower() or 'char' in data_type.lower() or 'text' in data_type.lower()
    if is_varchar:
        length_stats = f"""
        ,MIN(LENGTH(CAST({col_q} AS VARCHAR))) AS min_length,
        MAX(LENGTH(CAST({col_q} AS VARCHAR))) AS max_length
        """
    else:
        length_stats = ",NULL AS min_length, NULL AS max_length"
    
    # Duplication analysis (count rows where value appears more than once)
    dup_stats = f"""
    ,SUM(CASE 
        WHEN {col_q} IS NOT NULL AND 
             {col_q} IN (
                SELECT {col_q} FROM {fq} 
                WHERE {col_q} IS NOT NULL 
                GROUP BY {col_q} 
                HAVING COUNT(*) > 1
             )
        THEN 1 ELSE 0 END) AS duplicate_count
    """
    
    # Space and special character analysis (for string types)
    if is_varchar:
        quality_stats = f"""
        ,SUM(CASE WHEN {col_q} LIKE ' %' THEN 1 ELSE 0 END) AS leading_space_count,
        SUM(CASE WHEN {col_q} LIKE '% ' THEN 1 ELSE 0 END) AS trailing_space_count,
        SUM(CASE WHEN REGEXP_LIKE(CAST({col_q} AS VARCHAR), '[^a-zA-Z0-9 ]') THEN 1 ELSE 0 END) AS special_char_count,
        SUM(CASE WHEN REGEXP_LIKE(CAST({col_q} AS VARCHAR), '\s') THEN 1 ELSE 0 END) AS whitespace_count
        """
    else:
        quality_stats = """
        ,NULL AS leading_space_count,
        NULL AS trailing_space_count,
        NULL AS special_char_count,
        NULL AS whitespace_count
        """
    
    return f"SELECT {base_stats}{length_stats}{dup_stats}{quality_stats} FROM {fq}"


@cache_data(ttl=900, show_spinner=False)
def compute_enhanced_data_quality(catalog: str, schema: str, table: str, workers: int = DEFAULT_WORKERS) -> pd.DataFrame:
    """Compute enhanced data quality metrics with advanced checks."""
    cols_df = get_columns(catalog, schema, table)
    if cols_df.empty:
        return pd.DataFrame()

    col_info = [(row['column_name'], row['data_type']) for _, row in cols_df.iterrows()]

    results: List[pd.DataFrame] = []
    with ThreadPoolExecutor(max_workers=workers) as ex:
        futures = {ex.submit(run_sql, _dq_sql_for_column(catalog, schema, table, c, dt)): (c, dt) 
                   for c, dt in col_info}
        for fut in as_completed(futures):
            col, dt = futures[fut]
            try:
                rows, cols = fut.result()
                df = pd.DataFrame(rows, columns=cols)
                results.append(df)
            except Exception as e:
                # Fallback with NULLs
                results.append(pd.DataFrame([{
                    "column_name": col,
                    "data_type": dt,
                    "total_rows": None,
                    "null_count": None,
                    "approx_unique_count": None,
                    "min_value": None,
                    "max_value": None,
                    "min_length": None,
                    "max_length": None,
                    "duplicate_count": None,
                    "leading_space_count": None,
                    "trailing_space_count": None,
                    "special_char_count": None,
                    "whitespace_count": None
                }]))

    if not results:
        return pd.DataFrame()

    out = pd.concat(results, ignore_index=True).sort_values("column_name")

    # Calculate percentages
    def pct(a, b):
        try:
            if b in (0, None) or a is None:
                return None
            return round((a / b) * 100.0, 2)
        except Exception:
            return None

    out["null_pct"] = [pct(n, t) for n, t in zip(out["null_count"], out["total_rows"])]
    
    # Clamp unique_pct to 100%
    clamped_unique_pct = []
    for u, t in zip(out["approx_unique_count"], out["total_rows"]):
        if t in (0, None):
            clamped_unique_pct.append(None)
            continue
        u_num = float(u) if u is not None else 0.0
        t_num = float(t)
        ratio = min(u_num, t_num) / t_num * 100.0
        clamped_unique_pct.append(round(ratio, 2))
    out["unique_pct"] = clamped_unique_pct
    
    out["duplicate_pct"] = [pct(d, t) for d, t in zip(out["duplicate_count"], out["total_rows"])]
    out["leading_space_pct"] = [pct(l, t) for l, t in zip(out["leading_space_count"], out["total_rows"])]
    out["trailing_space_pct"] = [pct(tr, t) for tr, t in zip(out["trailing_space_count"], out["total_rows"])]
    out["special_char_pct"] = [pct(s, t) for s, t in zip(out["special_char_count"], out["total_rows"])]
    out["whitespace_pct"] = [pct(w, t) for w, t in zip(out["whitespace_count"], out["total_rows"])]

    return out


# =========================
# Blast Radius
# =========================
def jaccard(a: List[str], b: List[str]) -> float:
    sa, sb = set([x.lower() for x in a]), set([x.lower() for x in b])
    if not sa and not sb:
        return 1.0
    if not sa or not sb:
        return 0.0
    inter = len(sa & sb)
    union = len(sa | sb)
    return inter / union if union else 0.0


@cache_data(ttl=900, show_spinner=False)
def blast_radius_analysis(catalog: str, schema: str, table: str, neighbors_limit: int = 25) -> Tuple[float, pd.DataFrame]:
    """Compute blast radius analysis."""
    all_tables = list_tables(catalog, schema)
    empty_cols = ["base_table", "related_table", "relationship", "jaccard", "shared_columns_count", "total_columns", "shared_columns_sample"]

    if not all_tables or table not in all_tables:
        return 0.0, pd.DataFrame(columns=empty_cols)

    base_cols_df = get_columns(catalog, schema, table)
    base_cols = base_cols_df["column_name"].tolist() if not base_cols_df.empty else []

    def looks_like_key(c: str) -> bool:
        cl = c.lower()
        return cl == "id" or cl.endswith("_id") or cl.endswith("id")

    keyish = {c.lower() for c in base_cols if looks_like_key(c)}
    base_set = set(c.lower() for c in base_cols)

    related_rows = []
    for t in all_tables:
        if t == table:
            continue
        df = get_columns(catalog, schema, t)
        other_cols = df["column_name"].tolist() if not df.empty else []
        jac = jaccard(base_cols, other_cols)
        other_set = set(c.lower() for c in other_cols)
        shared = sorted(list(base_set & other_set))

        has_jaccard = jac >= JACCARD_THRESHOLD
        has_keyoverlap = bool(keyish and keyish.intersection(other_set))

        if has_jaccard or has_keyoverlap:
            if has_jaccard and has_keyoverlap:
                relation = "both (schema-similar + key-overlap)"
            elif has_jaccard:
                relation = f"schema-similar (Jaccard ‚â• {JACCARD_THRESHOLD})"
            else:
                relation = "key-overlap"

            related_rows.append({
                "base_table": table,
                "related_table": t,
                "relationship": relation,
                "jaccard": round(jac, 3),
                "shared_columns_count": len(shared),
                "total_columns": len(other_cols),
                "shared_columns_sample": ", ".join(shared[:8])
            })

    related_df = pd.DataFrame(related_rows, columns=empty_cols)
    if related_df.empty:
        return 0.0, related_df

    sort_keys = [c for c in ["jaccard", "shared_columns_count"] if c in related_df.columns]
    if sort_keys:
        related_df = related_df.sort_values(sort_keys, ascending=[False] * len(sort_keys))

    total_others = max(len(all_tables) - 1, 1)
    score = min(1.0, len(related_df) / total_others)

    if neighbors_limit and not related_df.empty:
        related_df = related_df.head(neighbors_limit)

    return round(score, 3), related_df.reset_index(drop=True)


# =========================
# Modern Professional Styles
# =========================
def apply_styles() -> None:
    st.set_page_config(page_title=APP_TITLE, layout="wide", page_icon="‚ùÑÔ∏è")
    st.markdown(
        """
        <style>
          /* Modern Bright Professional Theme */
          :root {
            --primary: #3B82F6;
            --primary-light: #60A5FA;
            --primary-dark: #2563EB;
            --secondary: #8B5CF6;
            --success: #10B981;
            --warning: #F59E0B;
            --danger: #EF4444;
            --info: #06B6D4;
            --bg-main: #F8FAFC;
            --bg-card: #FFFFFF;
            --bg-sidebar: #1E293B;
            --text-primary: #0F172A;
            --text-secondary: #64748B;
            --border: #E2E8F0;
            --shadow: rgba(0, 0, 0, 0.1);
            --gradient-1: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            --gradient-2: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            --gradient-3: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
            --gradient-4: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%);
          }

          /* Main Layout */
          html, body, .block-container {
            background: var(--bg-main) !important;
            color: var(--text-primary);
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
          }

          .block-container {
            padding-top: 2rem !important;
            max-width: 1600px;
          }

          /* Modern Header with Gradient */
          .app-header {
            background: var(--gradient-1);
            padding: 2rem 2.5rem;
            border-radius: 20px;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px var(--shadow);
            position: relative;
            overflow: hidden;
          }

          .app-header::before {
            content: '';
            position: absolute;
            top: 0;
            right: 0;
            width: 300px;
            height: 300px;
            background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
            border-radius: 50%;
            transform: translate(50%, -50%);
          }

          .app-header h1 {
            margin: 0;
            color: white;
            font-size: 2.5rem;
            font-weight: 700;
            text-shadow: 0 2px 4px rgba(0,0,0,0.1);
          }

          .app-header p {
            margin: 0.5rem 0 0 0;
            color: rgba(255,255,255,0.95);
            font-size: 1.1rem;
            font-weight: 400;
          }

          /* Vibrant Metric Cards */
          .metric-card {
            background: var(--bg-card);
            border: 2px solid var(--border);
            border-radius: 16px;
            padding: 1.5rem;
            text-align: center;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            box-shadow: 0 4px 6px var(--shadow);
            position: relative;
            overflow: hidden;
          }

          .metric-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: var(--gradient-3);
          }

          .metric-card:hover {
            transform: translateY(-4px);
            box-shadow: 0 12px 24px var(--shadow);
            border-color: var(--primary);
          }

          .metric-icon {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            filter: drop-shadow(0 2px 4px var(--shadow));
          }

          .metric-value {
            font-size: 2.2rem;
            font-weight: 800;
            background: var(--gradient-1);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin: 0.5rem 0;
          }

          .metric-label {
            color: var(--text-secondary);
            font-size: 0.85rem;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            font-weight: 600;
          }

          /* Status Badges */
          .status-badge {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            border-radius: 50px;
            font-size: 0.85rem;
            font-weight: 600;
            box-shadow: 0 2px 4px var(--shadow);
          }

          .status-success { 
            background: linear-gradient(135deg, #10B981 0%, #059669 100%);
            color: white;
          }
          
          .status-danger { 
            background: linear-gradient(135deg, #EF4444 0%, #DC2626 100%);
            color: white;
          }

          .status-warning {
            background: linear-gradient(135deg, #F59E0B 0%, #D97706 100%);
            color: white;
          }

          .status-info {
            background: linear-gradient(135deg, #06B6D4 0%, #0891B2 100%);
            color: white;
          }

          /* Sidebar Styling */
          section[data-testid="stSidebar"] { 
            background: var(--bg-sidebar);
            border-right: 1px solid var(--border);
          }
          
          section[data-testid="stSidebar"] .stMarkdown h3 {
            color: var(--primary-light);
            font-size: 0.9rem;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            margin-top: 1.5rem;
            margin-bottom: 0.8rem;
            font-weight: 700;
          }

          section[data-testid="stSidebar"] label {
            color: #CBD5E1 !important;
            font-weight: 500;
          }

          /* Modern Tabs */
          .stTabs [data-baseweb="tab-list"] {
            gap: 12px;
            background: var(--bg-card);
            padding: 0.75rem;
            border-radius: 16px;
            box-shadow: 0 2px 8px var(--shadow);
          }
          
          .stTabs [data-baseweb="tab"] {
            border-radius: 12px;
            padding: 0.75rem 1.5rem;
            font-weight: 600;
            color: var(--text-secondary);
            transition: all 0.3s;
          }

          .stTabs [data-baseweb="tab"]:hover {
            background: var(--bg-main);
          }

          .stTabs [data-baseweb="tab"][aria-selected="true"] {
            background: var(--gradient-1);
            color: white !important;
          }

          /* Info Boxes */
          .info-box {
            background: linear-gradient(135deg, #EFF6FF 0%, #DBEAFE 100%);
            border-left: 5px solid var(--primary);
            padding: 1.25rem;
            border-radius: 12px;
            margin: 1rem 0;
            box-shadow: 0 2px 8px var(--shadow);
          }

          .warning-box {
            background: linear-gradient(135deg, #FEF3C7 0%, #FDE68A 100%);
            border-left: 5px solid var(--warning);
            padding: 1.25rem;
            border-radius: 12px;
            margin: 1rem 0;
            box-shadow: 0 2px 8px var(--shadow);
          }

          .success-box {
            background: linear-gradient(135deg, #D1FAE5 0%, #A7F3D0 100%);
            border-left: 5px solid var(--success);
            padding: 1.25rem;
            border-radius: 12px;
            margin: 1rem 0;
            box-shadow: 0 2px 8px var(--shadow);
          }

          /* Buttons */
          .stButton > button {
            border-radius: 12px;
            font-weight: 600;
            transition: all 0.3s;
            border: none;
            box-shadow: 0 4px 6px var(--shadow);
          }
          
          .stButton > button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 12px var(--shadow);
          }

          .stButton > button[kind="primary"] {
            background: var(--gradient-1) !important;
          }

          /* DataFrames */
          .stDataFrame {
            border-radius: 12px !important;
            overflow: hidden;
            box-shadow: 0 4px 6px var(--shadow) !important;
          }

          /* Download Button */
          .stDownloadButton > button {
            background: var(--gradient-4) !important;
            color: var(--text-primary) !important;
            font-weight: 600;
          }

          /* Quality Score Badge */
          .quality-score {
            display: inline-block;
            padding: 0.75rem 1.5rem;
            border-radius: 50px;
            font-size: 1.5rem;
            font-weight: 800;
            text-align: center;
            box-shadow: 0 4px 12px var(--shadow);
            min-width: 120px;
          }

          .quality-excellent {
            background: linear-gradient(135deg, #10B981 0%, #059669 100%);
            color: white;
          }

          .quality-good {
            background: linear-gradient(135deg, #3B82F6 0%, #2563EB 100%);
            color: white;
          }

          .quality-fair {
            background: linear-gradient(135deg, #F59E0B 0%, #D97706 100%);
            color: white;
          }

          .quality-poor {
            background: linear-gradient(135deg, #EF4444 0%, #DC2626 100%);
            color: white;
          }
        </style>
        """,
        unsafe_allow_html=True
    )


# =========================
# UI Components
# =========================
def render_header():
    st.markdown(
        f"""
        <div class="app-header">
            <h1>‚ùÑÔ∏è {APP_TITLE}</h1>
            <p>Professional-grade data quality analysis, blast radius detection, and comprehensive metadata exploration</p>
        </div>
        """,
        unsafe_allow_html=True
    )


def render_metrics(catalogs: List[str], schemas: List[str], tables: List[str]):
    cols = st.columns(4)
    metrics = [
        ("Catalogs", len(catalogs), "üìä", "--gradient-1"),
        ("Schemas", len(schemas), "üìÅ", "--gradient-2"),
        ("Tables", len(tables), "üóÇÔ∏è", "--gradient-3"),
        ("Workers", DEFAULT_WORKERS, "‚ö°", "--gradient-4")
    ]
    for col, (label, value, icon, gradient) in zip(cols, metrics):
        with col:
            st.markdown(
                f"""
                <div class="metric-card">
                    <div class="metric-icon">{icon}</div>
                    <div class="metric-value" style="background: var({gradient}); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">{value:,}</div>
                    <div class="metric-label">{label}</div>
                </div>
                """,
                unsafe_allow_html=True
            )


def sidebar_config() -> Dict:
    st.sidebar.title("‚öôÔ∏è Configuration")

    # Connection Status
    st.sidebar.markdown("### üîå Connection")
    try:
        _ = run_sql("SELECT 1")
        st.sidebar.markdown('<span class="status-badge status-success">‚óè Connected</span>', unsafe_allow_html=True)
    except Exception as e:
        st.sidebar.markdown('<span class="status-badge status-danger">‚óè Disconnected</span>', unsafe_allow_html=True)
        st.sidebar.error(f"Error: {str(e)[:160]}")
        st.stop()

    st.sidebar.markdown("### üìç Location")
    catalogs = list_catalogs()
    if not catalogs:
        st.sidebar.error("No catalogs available")
        st.stop()

    if "catalog" not in st.session_state:
        st.session_state.catalog = catalogs[0]

    catalog = st.sidebar.selectbox("Catalog", catalogs, index=catalogs.index(st.session_state.catalog) if st.session_state.catalog in catalogs else 0)
    st.session_state.catalog = catalog

    schemas = list_schemas(catalog)
    if not schemas:
        st.sidebar.error("No schemas available")
        st.stop()

    if "schema" not in st.session_state or st.session_state.schema not in schemas:
        st.session_state.schema = schemas[0]

    schema = st.sidebar.selectbox("Schema", schemas, index=schemas.index(st.session_state.schema) if st.session_state.schema in schemas else 0)
    st.session_state.schema = schema

    tables = list_tables(catalog, schema)
    if "preview_limit" not in st.session_state:
        st.session_state.preview_limit = DEFAULT_PREVIEW

    st.sidebar.markdown("### üì¶ Preview")
    preview_limit = st.sidebar.slider("Preview rows", 10, 500, st.session_state.preview_limit, step=10)
    st.session_state.preview_limit = preview_limit

    st.sidebar.markdown("### üßµ Parallelism")
    workers = st.sidebar.slider("Workers", 2, 32, DEFAULT_WORKERS)

    return {"catalog": catalog, "schema": schema, "preview_limit": preview_limit, "workers": workers}


def render_table_browser(catalog: str, schema: str, preview_limit: int) -> Optional[str]:
    st.subheader("üìä Browse & Profile")
    tables = list_tables(catalog, schema)
    if not tables:
        st.info("No tables in this schema")
        return None

    left, right = st.columns([2, 3])
    with left:
        selected = st.selectbox("Select a table", tables)
        cols_df = get_columns(catalog, schema, selected)
        st.markdown("**Columns**")
        st.dataframe(ensure_arrow_compat(cols_df), use_container_width=True, height=280)

    with right:
        st.markdown("**Preview**")
        with st.spinner("Loading preview..."):
            try:
                df = preview_table(catalog, schema, selected, limit=preview_limit)
                if df is None or df.empty:
                    st.info("Table is empty")
                else:
                    st.dataframe(ensure_arrow_compat(df), use_container_width=True, height=360)
            except Exception as e:
                st.error(f"Preview failed: {str(e)[:200]}")

    return selected


def get_quality_score_html(score: float) -> str:
    """Generate HTML for quality score display."""
    if score >= 90:
        cls = "quality-excellent"
        label = "Excellent"
    elif score >= 75:
        cls = "quality-good"
        label = "Good"
    elif score >= 50:
        cls = "quality-fair"
        label = "Fair"
    else:
        cls = "quality-poor"
        label = "Poor"
    
    return f'<div class="quality-score {cls}">{score:.1f}% {label}</div>'


def calculate_overall_quality_score(dq_df: pd.DataFrame) -> float:
    """Calculate an overall quality score based on various metrics."""
    if dq_df.empty:
        return 0.0
    
    scores = []
    
    # Completeness score (lower null percentage is better)
    avg_null_pct = dq_df['null_pct'].fillna(0).mean()
    completeness = max(0, 100 - avg_null_pct)
    scores.append(completeness)
    
    # Uniqueness score (higher unique percentage is better for some columns)
    avg_unique_pct = dq_df['unique_pct'].fillna(0).mean()
    scores.append(min(avg_unique_pct, 100))
    
    # Duplication score (lower duplication is better)
    avg_dup_pct = dq_df['duplicate_pct'].fillna(0).mean()
    duplication = max(0, 100 - avg_dup_pct)
    scores.append(duplication)
    
    # Space/special char cleanliness (lower is better)
    avg_space_issues = (
        dq_df['leading_space_pct'].fillna(0).mean() + 
        dq_df['trailing_space_pct'].fillna(0).mean()
    ) / 2
    cleanliness = max(0, 100 - avg_space_issues)
    scores.append(cleanliness)
    
    return sum(scores) / len(scores) if scores else 0.0


def render_data_quality_tab(catalog: str, schema: str, selected_table: Optional[str], workers: int):
    st.subheader("üß™ Enhanced Data Quality Analysis")
    
    if not selected_table:
        st.markdown(
            """
            <div class="info-box">
                <h4 style="margin-top: 0;">üëà Select a table to begin</h4>
                <p style="margin-bottom: 0;">Choose a table from the Browse & Profile tab to perform comprehensive data quality analysis including:</p>
                <ul>
                    <li><strong>Basic Stats:</strong> Null counts, unique values, min/max</li>
                    <li><strong>VARCHAR Analysis:</strong> Actual data length ranges</li>
                    <li><strong>Duplication Detection:</strong> Identify duplicate values</li>
                    <li><strong>Space Issues:</strong> Leading/trailing spaces</li>
                    <li><strong>Special Characters:</strong> Non-alphanumeric content</li>
                    <li><strong>Whitespace Analysis:</strong> Embedded spaces and tabs</li>
                </ul>
            </div>
            """,
            unsafe_allow_html=True
        )
        return

    st.markdown(f"**Analyzing:** `{catalog}.{schema}.{selected_table}`")

    if st.button("‚ñ∂Ô∏è Run Enhanced Data Quality Analysis", type="primary", use_container_width=True):
        # Zero-row guard
        if not table_has_rows(catalog, schema, selected_table):
            st.markdown(
                """
                <div class="warning-box">
                    <strong>‚ö†Ô∏è Warning:</strong> Row count is zero ‚Äî nothing to analyze.
                </div>
                """,
                unsafe_allow_html=True
            )
            return

        with st.spinner("üîç Computing comprehensive quality metrics..."):
            dq = compute_enhanced_data_quality(catalog, schema, selected_table, workers=workers)
            
            if dq is not None and not dq.empty:
                # Calculate overall quality score
                quality_score = calculate_overall_quality_score(dq)
                
                st.markdown(
                    f"""
                    <div class="success-box">
                        <h4 style="margin-top: 0;">‚úÖ Analysis Complete</h4>
                        <p style="margin-bottom: 0.5rem;">Overall Data Quality Score:</p>
                        {get_quality_score_html(quality_score)}
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                
                # Summary metrics in colorful cards
                col1, col2, col3, col4 = st.columns(4)
                
                avg_null = dq['null_pct'].fillna(0).mean()
                avg_dup = dq['duplicate_pct'].fillna(0).mean()
                avg_spaces = (dq['leading_space_pct'].fillna(0).mean() + dq['trailing_space_pct'].fillna(0).mean()) / 2
                avg_special = dq['special_char_pct'].fillna(0).mean()
                
                with col1:
                    null_status = "status-success" if avg_null < 5 else "status-warning" if avg_null < 20 else "status-danger"
                    st.markdown(
                        f"""
                        <div class="metric-card">
                            <div class="metric-icon">üìä</div>
                            <div class="metric-value" style="background: var(--gradient-2); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">{avg_null:.1f}%</div>
                            <div class="metric-label">Avg Null Rate</div>
                            <div style="margin-top: 0.5rem;"><span class="status-badge {null_status}">{'Excellent' if avg_null < 5 else 'Fair' if avg_null < 20 else 'Poor'}</span></div>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                
                with col2:
                    dup_status = "status-success" if avg_dup < 5 else "status-warning" if avg_dup < 20 else "status-danger"
                    st.markdown(
                        f"""
                        <div class="metric-card">
                            <div class="metric-icon">üîÑ</div>
                            <div class="metric-value" style="background: var(--gradient-3); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">{avg_dup:.1f}%</div>
                            <div class="metric-label">Avg Duplication</div>
                            <div style="margin-top: 0.5rem;"><span class="status-badge {dup_status}">{'Excellent' if avg_dup < 5 else 'Fair' if avg_dup < 20 else 'Poor'}</span></div>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                
                with col3:
                    space_status = "status-success" if avg_spaces < 1 else "status-warning" if avg_spaces < 5 else "status-danger"
                    st.markdown(
                        f"""
                        <div class="metric-card">
                            <div class="metric-icon">‚éµ</div>
                            <div class="metric-value" style="background: var(--gradient-4); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">{avg_spaces:.1f}%</div>
                            <div class="metric-label">Avg Space Issues</div>
                            <div style="margin-top: 0.5rem;"><span class="status-badge {space_status}">{'Excellent' if avg_spaces < 1 else 'Fair' if avg_spaces < 5 else 'Poor'}</span></div>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                
                with col4:
                    special_status = "status-info" if avg_special < 50 else "status-warning"
                    st.markdown(
                        f"""
                        <div class="metric-card">
                            <div class="metric-icon">üî£</div>
                            <div class="metric-value" style="background: var(--gradient-1); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">{avg_special:.1f}%</div>
                            <div class="metric-label">Special Chars</div>
                            <div style="margin-top: 0.5rem;"><span class="status-badge {special_status}">{'Normal' if avg_special < 50 else 'High'}</span></div>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                
                st.markdown("---")
                
                # Detailed table
                st.markdown("### üìã Detailed Column Analysis")
                
                # Reorder columns for better readability
                display_cols = [
                    'column_name', 'data_type', 'total_rows', 'null_count', 'null_pct',
                    'approx_unique_count', 'unique_pct', 'duplicate_count', 'duplicate_pct',
                    'min_length', 'max_length', 'min_value', 'max_value',
                    'leading_space_count', 'leading_space_pct', 'trailing_space_count', 'trailing_space_pct',
                    'special_char_count', 'special_char_pct', 'whitespace_count', 'whitespace_pct'
                ]
                
                # Only show columns that exist
                display_cols = [c for c in display_cols if c in dq.columns]
                dq_display = dq[display_cols]
                
                st.dataframe(ensure_arrow_compat(dq_display), use_container_width=True, height=500)
                
                # Download button
                csv = dq.to_csv(index=False)
                st.download_button(
                    "‚¨áÔ∏è Download Complete DQ Report",
                    csv,
                    f"{selected_table}_enhanced_dq_report.csv",
                    "text/csv",
                    use_container_width=True
                )
                
                # Insights section
                st.markdown("### üí° Key Insights")
                insights_cols = st.columns(2)
                
                with insights_cols[0]:
                    # High null columns
                    high_null = dq[dq['null_pct'] > 50].sort_values('null_pct', ascending=False)
                    if not high_null.empty:
                        st.markdown("**‚ö†Ô∏è High Null Columns (>50%)**")
                        for _, row in high_null.head(5).iterrows():
                            st.markdown(f"- `{row['column_name']}`: {row['null_pct']:.1f}% nulls")
                    
                    # High duplication
                    high_dup = dq[dq['duplicate_pct'] > 20].sort_values('duplicate_pct', ascending=False)
                    if not high_dup.empty:
                        st.markdown("**üîÑ High Duplication Columns (>20%)**")
                        for _, row in high_dup.head(5).iterrows():
                            st.markdown(f"- `{row['column_name']}`: {row['duplicate_pct']:.1f}% duplicates")
                
                with insights_cols[1]:
                    # Space issues
                    space_issues = dq[(dq['leading_space_pct'] > 1) | (dq['trailing_space_pct'] > 1)]
                    if not space_issues.empty:
                        st.markdown("**‚éµ Columns with Space Issues (>1%)**")
                        for _, row in space_issues.head(5).iterrows():
                            issues = []
                            if row['leading_space_pct'] > 1:
                                issues.append(f"leading: {row['leading_space_pct']:.1f}%")
                            if row['trailing_space_pct'] > 1:
                                issues.append(f"trailing: {row['trailing_space_pct']:.1f}%")
                            st.markdown(f"- `{row['column_name']}`: {', '.join(issues)}")
                    
                    # VARCHAR length insights
                    varchar_cols = dq[(dq['min_length'].notna()) & (dq['max_length'].notna())]
                    if not varchar_cols.empty:
                        st.markdown("**üìè VARCHAR Length Ranges**")
                        for _, row in varchar_cols.head(5).iterrows():
                            st.markdown(f"- `{row['column_name']}`: {row['min_length']} to {row['max_length']} chars")
            
            else:
                st.markdown(
                    """
                    <div class="warning-box">
                        <strong>‚ö†Ô∏è No statistics available</strong> for this table.
                    </div>
                    """,
                    unsafe_allow_html=True
                )


def render_blast_radius_tab(catalog: str, schema: str, selected_table: Optional[str]):
    st.subheader("üí• Blast Radius & Similarity Analysis")
    
    if not selected_table:
        st.markdown(
            """
            <div class="info-box">
                <h4 style="margin-top: 0;">üëà Select a table to begin</h4>
                <p style="margin-bottom: 0;">Blast Radius analysis helps you understand the potential impact of changes to a table by identifying related tables through column similarity and key relationships.</p>
            </div>
            """,
            unsafe_allow_html=True
        )
        return

    st.markdown(
        f"""
        <div class="info-box">
          <strong>üéØ Blast Radius Analysis</strong><br/>
          Estimates how many tables in the schema are likely impacted if the selected table changes or breaks.
          Uses <i>column-set similarity (Jaccard)</i> and <i>key-like overlaps</i> (id, *_id) as proxies.
          <div style="margin-top: 8px;">
            <strong>Base Table:</strong> <code>{catalog}.{schema}.{selected_table}</code>
          </div>
        </div>
        """,
        unsafe_allow_html=True
    )

    with st.spinner("üîç Analyzing table relationships..."):
        score, related = blast_radius_analysis(catalog, schema, selected_table, neighbors_limit=25)

    c1, c2, c3 = st.columns([1, 1, 2])
    
    with c1:
        # Blast radius score
        score_pct = score * 100
        if score_pct >= 50:
            score_class = "quality-poor"
            impact = "Critical"
        elif score_pct >= 25:
            score_class = "quality-warning"
            impact = "High"
        elif score_pct >= 10:
            score_class = "quality-fair"
            impact = "Moderate"
        else:
            score_class = "quality-good"
            impact = "Low"
        
        st.markdown(
            f"""
            <div class="metric-card">
                <div class="metric-icon">üî•</div>
                <div class="quality-score {score_class}">{score_pct:.1f}%</div>
                <div class="metric-label">Blast Radius Score</div>
            </div>
            """,
            unsafe_allow_html=True
        )
    
    with c2:
        related_count = len(related) if related is not None and not related.empty else 0
        st.markdown(
            f"""
            <div class="metric-card">
                <div class="metric-icon">üîó</div>
                <div class="metric-value" style="background: var(--gradient-3); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">{related_count}</div>
                <div class="metric-label">Related Tables</div>
            </div>
            """,
            unsafe_allow_html=True
        )
    
    with c3:
        st.markdown(
            f"""
            <div class="info-box" style="margin-top: 0;">
                <strong>Impact Level: {impact}</strong><br/>
                {'‚ö†Ô∏è Changes to this table may affect many downstream tables' if score_pct >= 25 else '‚úÖ Limited impact expected from changes'}
            </div>
            """,
            unsafe_allow_html=True
        )

    st.markdown("---")

    if related is None or related.empty or "jaccard" not in related.columns:
        st.markdown(
            """
            <div class="success-box">
                <strong>‚úÖ No closely related tables detected</strong><br/>
                This table appears to be relatively isolated in the schema.
            </div>
            """,
            unsafe_allow_html=True
        )
    else:
        st.markdown("### üîó Related Tables & Relationships")
        st.dataframe(
            ensure_arrow_compat(
                related[
                    ["base_table", "related_table", "relationship", "jaccard",
                     "shared_columns_count", "total_columns", "shared_columns_sample"]
                ]
            ),
            use_container_width=True,
            height=450
        )
        
        csv = related.to_csv(index=False)
        st.download_button(
            "‚¨áÔ∏è Download Relationship Report",
            csv,
            f"{selected_table}_blast_radius_report.csv",
            "text/csv",
            use_container_width=True
        )


def render_search_tab(catalog: str, schema: str):
    st.subheader("üîé Metadata Search")
    st.markdown(
        """
        <div class="info-box">
          <strong>üîç Search across all tables and columns</strong> in the selected schema.
          Find tables containing specific columns, data types, or any metadata.
        </div>
        """,
        unsafe_allow_html=True
    )
    
    col1, col2 = st.columns([3, 1])
    with col1:
        query = st.text_input(
            "Search query",
            placeholder="e.g., customer_id, email, timestamp, varchar...",
            label_visibility="collapsed"
        )
    with col2:
        mode = st.selectbox("Mode", ["Column name", "Any field"], label_visibility="collapsed")

    if query:
        with st.spinner("üîç Searching metadata..."):
            all_cols = get_all_columns_in_schema(catalog, schema)
            if all_cols.empty:
                st.info("No metadata found.")
                return

            q = query.lower()
            if mode == "Column name":
                mask = all_cols["column_name"].str.lower().str.contains(re.escape(q), na=False)
            else:
                mask = (
                    all_cols["table_name"].str.lower().str.contains(re.escape(q), na=False) |
                    all_cols["column_name"].str.lower().str.contains(re.escape(q), na=False) |
                    all_cols["data_type"].str.lower().str.contains(re.escape(q), na=False)
                )
            out = all_cols.loc[mask].sort_values(["table_name", "ordinal_position"])
            
            if not out.empty:
                st.markdown(
                    f"""
                    <div class="success-box">
                        <strong>‚úÖ Found {len(out):,} matching columns</strong> across {out['table_name'].nunique()} tables
                    </div>
                    """,
                    unsafe_allow_html=True
                )
                st.dataframe(ensure_arrow_compat(out), use_container_width=True, height=450)
            else:
                st.markdown(
                    """
                    <div class="warning-box">
                        <strong>No matches found</strong> for your search query. Try different keywords.
                    </div>
                    """,
                    unsafe_allow_html=True
                )


# =========================
# Main Application
# =========================
def main():
    apply_styles()
    render_header()

    config = sidebar_config()
    catalog = config["catalog"]
    schema = config["schema"]

    catalogs = list_catalogs()
    schemas = list_schemas(catalog)
    tables = list_tables(catalog, schema)

    render_metrics(catalogs, schemas, tables)

    st.markdown("---")

    tab1, tab2, tab3, tab4 = st.tabs([
        "üìä Browse & Profile",
        "üß™ Data Quality",
        "üí• Blast Radius",
        "üîé Search"
    ])

    with tab1:
        selected_table = render_table_browser(catalog, schema, config["preview_limit"])
        st.session_state.selected_table = selected_table

    with tab2:
        render_data_quality_tab(catalog, schema, st.session_state.get("selected_table"), workers=config["workers"])

    with tab3:
        render_blast_radius_tab(catalog, schema, st.session_state.get("selected_table"))

    with tab4:
        render_search_tab(catalog, schema)


if __name__ == "__main__":
    main()
